{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMS/VJfz5Gggg8FujH+golh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayhanbzkrt/Deep-Learning-Tutorial/blob/main/Deep_Learning_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxyqgqndcHx2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning Tutorial\n",
        "\n",
        "Welcome to this comprehensive Deep Learning tutorial. Designed to introduce you to the world of neural networks, advanced architectures, and practical applications, this tutorial offers insights into why deep learning is a major driving force behind the advancements in artificial intelligence.\n",
        "\n",
        "## üìò Table of Contents\n",
        "\n",
        "- **[Introduction](#introduction)**\n",
        "- **[Feedforward Neural Networks](#feedforward-neural-networks)**\n",
        "- **[Convolutional Neural Networks (CNNs)](#convolutional-neural-networks)**\n",
        "- **[Recurrent Neural Networks (RNNs) and LSTM](#recurrent-neural-networks)**\n",
        "- **[Transfer Learning](#transfer-learning)**\n",
        "- **[Regularization and Optimization](#regularization-and-optimization)**\n",
        "- **[Tools and Libraries](#tools-and-libraries)**\n",
        "- **[Conclusion and Future Trends](#conclusion-and-future-trends)**\n",
        "\n",
        "## üéØ Objective\n",
        "\n",
        "This tutorial aims to serve both beginners, who might be new to the deep learning domain, and seasoned practitioners looking for a refresher or deeper insights. With hands-on coding examples, detailed explanations, and practical applications, we strive to offer a holistic understanding of the vast landscape of deep learning.\n",
        "\n",
        "## üöÄ Getting Started\n",
        "\n",
        "It's recommended to navigate through the topics in a sequential manner, as each section often builds upon the concepts introduced in the prior sections. Throughout the tutorial, you'll encounter code snippets, visualizations, and comprehensive explanations to elucidate intricate topics.\n",
        "\n",
        "## üí¨ Feedback\n",
        "\n",
        "Your feedback plays a pivotal role in enhancing this tutorial. Should you come across any errors, or if you have suggestions or topics to discuss further, kindly raise an issue or contribute to this repository.\n",
        "\n",
        "**Happy Learning! üß†**\n"
      ],
      "metadata": {
        "id": "8_7ndExdcPKo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üê§Introduction\n",
        "\n",
        "**What is Deep Learning?**\n",
        "Deep Learning, essentially, is a subset of Machine Learning where algorithms are inspired by the structure and function of the brain called artificial neural networks. If Machine Learning is the high-level, broad overview of this type of artificial intelligence, then Deep Learning is the specialization of making this artificial intelligence as close as possible to human cognition through layers of neural networks.\n",
        "\n",
        "\n",
        "**Difference between Machine Learning and Deep Learning**\n",
        "\n",
        "Data Dependencies: Generally, Deep Learning requires more data than traditional Machine Learning algorithms. While Machine Learning can work with smaller datasets, Deep Learning benefits from larger datasets to improve its accuracy.\n",
        "\n",
        "Computational Complexities: Deep Learning typically requires more computation than Machine Learning. This is why we often see Deep Learning models being trained on GPUs or TPUs.\n",
        "\n",
        "**Feature Engineering:** In Machine Learning, a significant amount of time is spent on feature extraction. Deep Learning, on the other hand, tries to automatically extract features from raw data, thus reducing the need for manual feature engineering.\n",
        "\n",
        "\n",
        "**Interpretability:** Traditional Machine Learning models like decision trees are often easier to interpret than deep neural networks. Deep Learning models, due to their complexity, can sometimes act as \"black boxes\".\n",
        "\n",
        "Performance: As the volume of data grows, Deep Learning algorithms tend to outperform Machine Learning algorithms. This is because neural networks in Deep Learning improve their performance as the size of data increases.\n",
        "\n",
        "## ‚ú®Applications of Deep Learning\n",
        "\n",
        "Deep Learning has wide-ranging applications, such as:\n",
        "\n",
        "**Image and Voice Recognition:** Deep Learning can be used to identify objects in images or transcribe words spoken in audio.\n",
        "\n",
        "**Natural Language Processing (NLP):** For understanding and generating human languages.\n",
        "\n",
        "\n",
        "**Medical Diagnosis**: Analyzing medical images to detect diseases.\n",
        "Financial Fraud Detection: Spotting suspicious activities in financial transactions.\n",
        "\n",
        "**Self-driving cars:** Using sensors and onboard analytics to identify objects and make decisions."
      ],
      "metadata": {
        "id": "eZSLGLaNdFmf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚ùÑ Neural Networks: Building Blocks of Deep Learning\n",
        "\n",
        "**Basics of Neural Networks**\n",
        "\n",
        "At the heart of Deep Learning lies the concept of an artificial neural network. These are computational models inspired by the way the human brain works. They are made up of layers of neurons and can process data input to produce an output.\n",
        "\n",
        "**Structure of a Neural Network**\n",
        "\n",
        "**Input Layer:** This is the initial layer that takes in the data. It's the doorway through which data enters the network.\n",
        "\n",
        "\n",
        "**Hidden Layers:** After the input layer, there are one or more hidden layers. These layers do the computation and transform the input data.\n",
        "\n",
        "**Output Layer:** This is the final layer. It provides the result for given inputs.\n",
        "\n",
        "## üëæ Neurons: The Atoms of a Network\n",
        "\n",
        "Every single unit in the network is termed a neuron. These neurons take inputs, apply some function (generally non-linear) and then pass its result to the next layer.\n",
        "\n",
        "**Activation Functions**\n",
        "\n",
        "Once data has passed through the neuron, an activation function is applied. This determines if the neuron should be activated (\"fired\") or not, based on whether the neuron's input is relevant for the model's prediction. Common activation functions include ReLU (Rectified Linear Unit), Sigmoid, and Tanh.\n",
        "\n",
        "**Forward Propagation**\n",
        "\n",
        "Data moves through the neural network in a process called forward propagation. It starts at the input layer, moves through the hidden layers, and ends at the output layer.\n",
        "\n",
        "**Backpropagation and Learning**\n",
        "\n",
        "Backpropagation is an essential concept in neural networks. It refers to the method of calculating the gradient of the neural network's loss with respect to its weights. In essence, backpropagation helps the model 'learn' by adjusting its weights based on the error of its predictions.\n",
        "\n",
        "**Loss Functions**\n",
        "\n",
        "After forward propagation, we measure how good our predictions are with the help of a loss function. The goal of our network is to minimize this loss.\n",
        "\n",
        "**Optimizers**\n",
        "\n",
        "Optimizers are algorithms used to minimize the error in the network (i.e., the difference between the predicted output and the actual output). Common optimizers include Stochastic Gradient Descent (SGD), Adam, and RMSprop."
      ],
      "metadata": {
        "id": "hK923thjhT4e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alright! Let's solidify the topic with some hands-on examples. We will be using PyTorch to create a simple neural network.\n",
        "# ‚òï\n",
        "\n",
        "Deep Learning Example: A Simple Neural Network with PyTorch"
      ],
      "metadata": {
        "id": "cImJ8GdTiF7_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Import necessary libraries\n",
        "\n"
      ],
      "metadata": {
        "id": "Pwiz3Eh0ie9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n"
      ],
      "metadata": {
        "id": "jcAcgL9VihE5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Create a dataset\n",
        "\n",
        "For simplicity, we'll create a dataset where the input is a number, and the output is 1 if the number is even and 0 if it's odd."
      ],
      "metadata": {
        "id": "iH_rdXXhik0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data\n",
        "inputs = torch.tensor([[1.0], [2.0], [3.0], [4.0], [5.0], [6.0], [7.0], [8.0], [9.0], [10.0]])\n",
        "outputs = torch.tensor([[0.0], [1.0], [0.0], [1.0], [0.0], [1.0], [0.0], [1.0], [0.0], [1.0]])\n"
      ],
      "metadata": {
        "id": "ctDVVWuOin0f"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Define the Neural Network\n",
        "\n",
        "We'll define a simple feedforward neural network with one hidden layer."
      ],
      "metadata": {
        "id": "VDF-xwrCiqzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(1, 5)  # 1 input neuron, 5 hidden neurons\n",
        "        self.fc2 = nn.Linear(5, 1)  # 5 hidden neurons, 1 output neuron\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "model = SimpleNN()\n"
      ],
      "metadata": {
        "id": "7tBKpv9sitNU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Define the Loss function and Optimizer"
      ],
      "metadata": {
        "id": "TJSs--eHivxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.BCELoss()  # Binary Cross Entropy Loss\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)  # Stochastic Gradient Descent\n"
      ],
      "metadata": {
        "id": "PmqOCYp9ixle"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Train the Model\n",
        "\n",
        "We'll train the model for 1000 epochs."
      ],
      "metadata": {
        "id": "UwtCGRT2i0Zf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1000):\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(inputs)\n",
        "    loss = loss_function(predictions, outputs)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NaQSF0Bi1VN",
        "outputId": "f3b78eb2-f1e5-46cc-f5c8-d9e504393544"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.7055637240409851\n",
            "Epoch 100, Loss: 0.6947009563446045\n",
            "Epoch 200, Loss: 0.6929763555526733\n",
            "Epoch 300, Loss: 0.6914469599723816\n",
            "Epoch 400, Loss: 0.6901063919067383\n",
            "Epoch 500, Loss: 0.6889006495475769\n",
            "Epoch 600, Loss: 0.6878218650817871\n",
            "Epoch 700, Loss: 0.6868462562561035\n",
            "Epoch 800, Loss: 0.6860269904136658\n",
            "Epoch 900, Loss: 0.6853167414665222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Test the Model\n",
        "\n",
        "After training, we can test the model with some sample inputs."
      ],
      "metadata": {
        "id": "DBO46gZFi77B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = torch.tensor([[2.5], [3.5], [7.5]])\n",
        "predictions = model(test_data)\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XqUKXOhi-PW",
        "outputId": "9a93bb07-4d48-4db4-c1bf-94ad7f7ba595"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4795],\n",
            "        [0.4941],\n",
            "        [0.5484]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should see values close to 1 for even-like inputs and close to 0 for odd-like inputs.\n",
        "\n",
        "\n",
        "This simple example gives an introduction to creating and training a neural network using PyTorch. The next steps in deep learning involve exploring more complex architectures, regularization techniques, and much more!"
      ],
      "metadata": {
        "id": "C4InsJNXjCb5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Let's create a basic image classification example using the famous MNIST dataset. We'll create a simple convolutional neural network (CNN) using PyTorch to classify handwritten digits.\n",
        "\n",
        "**Deep Learning Example: Image Classification with CNN and PyTorch**"
      ],
      "metadata": {
        "id": "MEZY17C7jHT4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Import necessary libraries\n",
        "\n"
      ],
      "metadata": {
        "id": "keTSNaSejNW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n"
      ],
      "metadata": {
        "id": "aCoGP6m1jPP8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Load the dataset\n",
        "\n",
        "We'll use the torchvision library to load the MNIST dataset."
      ],
      "metadata": {
        "id": "gzMxLVrijR6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dERdCV0KjSoc",
        "outputId": "f600cc7b-6812-4a2c-f254-764472b65433"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9912422/9912422 [00:00<00:00, 81369431.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28881/28881 [00:00<00:00, 32554607.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1648877/1648877 [00:00<00:00, 180727294.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4542/4542 [00:00<00:00, 12986045.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Define the CNN"
      ],
      "metadata": {
        "id": "VAZYfBM0jXo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3)  # 1 input channel, 32 output channels, 3x3 kernel\n",
        "        self.fc1 = nn.Linear(32 * 26 * 26, 10)  # Image size reduces to 26x26 after convolution\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN()\n"
      ],
      "metadata": {
        "id": "R4fWzMAzjZlv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Define the Loss function and Optimizer"
      ],
      "metadata": {
        "id": "sW7XI50GjcqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n"
      ],
      "metadata": {
        "id": "EWXlOj-Fjefz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Train the Model\n",
        "\n",
        "Let's train the model for 5 epochs."
      ],
      "metadata": {
        "id": "WkXZmOCzjhrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = loss_function(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/5], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4J61GCcUjkgs",
        "outputId": "a4baa6e0-b4f6-466d-a0e8-1bc461f664ed"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [100/938], Loss: 0.4343\n",
            "Epoch [1/5], Step [200/938], Loss: 0.5242\n",
            "Epoch [1/5], Step [300/938], Loss: 0.4009\n",
            "Epoch [1/5], Step [400/938], Loss: 0.1235\n",
            "Epoch [1/5], Step [500/938], Loss: 0.2667\n",
            "Epoch [1/5], Step [600/938], Loss: 0.3104\n",
            "Epoch [1/5], Step [700/938], Loss: 0.3614\n",
            "Epoch [1/5], Step [800/938], Loss: 0.1603\n",
            "Epoch [1/5], Step [900/938], Loss: 0.1810\n",
            "Epoch [2/5], Step [100/938], Loss: 0.1664\n",
            "Epoch [2/5], Step [200/938], Loss: 0.3129\n",
            "Epoch [2/5], Step [300/938], Loss: 0.2178\n",
            "Epoch [2/5], Step [400/938], Loss: 0.2041\n",
            "Epoch [2/5], Step [500/938], Loss: 0.0930\n",
            "Epoch [2/5], Step [600/938], Loss: 0.3118\n",
            "Epoch [2/5], Step [700/938], Loss: 0.2664\n",
            "Epoch [2/5], Step [800/938], Loss: 0.1444\n",
            "Epoch [2/5], Step [900/938], Loss: 0.2492\n",
            "Epoch [3/5], Step [100/938], Loss: 0.1959\n",
            "Epoch [3/5], Step [200/938], Loss: 0.1424\n",
            "Epoch [3/5], Step [300/938], Loss: 0.2372\n",
            "Epoch [3/5], Step [400/938], Loss: 0.2327\n",
            "Epoch [3/5], Step [500/938], Loss: 0.1561\n",
            "Epoch [3/5], Step [600/938], Loss: 0.1292\n",
            "Epoch [3/5], Step [700/938], Loss: 0.1091\n",
            "Epoch [3/5], Step [800/938], Loss: 0.1983\n",
            "Epoch [3/5], Step [900/938], Loss: 0.2093\n",
            "Epoch [4/5], Step [100/938], Loss: 0.0959\n",
            "Epoch [4/5], Step [200/938], Loss: 0.1851\n",
            "Epoch [4/5], Step [300/938], Loss: 0.2150\n",
            "Epoch [4/5], Step [400/938], Loss: 0.0956\n",
            "Epoch [4/5], Step [500/938], Loss: 0.0473\n",
            "Epoch [4/5], Step [600/938], Loss: 0.1630\n",
            "Epoch [4/5], Step [700/938], Loss: 0.1544\n",
            "Epoch [4/5], Step [800/938], Loss: 0.1316\n",
            "Epoch [4/5], Step [900/938], Loss: 0.0746\n",
            "Epoch [5/5], Step [100/938], Loss: 0.1193\n",
            "Epoch [5/5], Step [200/938], Loss: 0.0733\n",
            "Epoch [5/5], Step [300/938], Loss: 0.0829\n",
            "Epoch [5/5], Step [400/938], Loss: 0.0505\n",
            "Epoch [5/5], Step [500/938], Loss: 0.1000\n",
            "Epoch [5/5], Step [600/938], Loss: 0.0625\n",
            "Epoch [5/5], Step [700/938], Loss: 0.0307\n",
            "Epoch [5/5], Step [800/938], Loss: 0.0778\n",
            "Epoch [5/5], Step [900/938], Loss: 0.0706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Evaluate the Model\n",
        "\n"
      ],
      "metadata": {
        "id": "2xbJpkmykhYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # Set the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the model on the 10000 test images: {100 * correct / total} %')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHZAmqFkkjux",
        "outputId": "87c3faa0-54d8-4d6b-ae10-ecd5157fe1c6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the 10000 test images: 95.74 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This example provides a brief introduction to using convolutional neural networks in PyTorch for image classification. To further improve accuracy, you can add more layers, introduce pooling, and use more advanced techniques!"
      ],
      "metadata": {
        "id": "svxKvH2-kos7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üßÆ Deep Neural Networks\n",
        "\n",
        "\n",
        "Deep Neural Networks (DNNs) refer to neural networks with a significant number of layers. These models are known to extract intricate patterns and representations from data, making them particularly valuable for complex tasks like image and speech recognition.\n",
        "\n",
        "\n",
        "**Benefits of Depth in Networks**\n",
        "\n",
        "**1. Hierarchical Feature Learning:**\n",
        "DNNs learn a hierarchy of features. In the context of image recognition, lower layers might recognize edges, the middle layers might recognize shapes, and the higher layers might recognize more complex structures. Each successive layer builds upon the previous one to recognize more abstract features.\n",
        "\n",
        "\n",
        "**Example:** In image recognition tasks, the first layer might recognize edges, the second layer could identify textures or shapes, and further layers might detect complex structures like a face or an object.\n",
        "\n",
        "**2. Improved Performance:**\n",
        "Given enough data, deeper networks can lead to improved accuracy and performance on training and validation datasets.\n",
        "\n",
        "\n",
        "**3. Reduced Feature Engineering:**\n",
        "DNNs can automatically extract and learn features from raw data, which can reduce the need for manual feature engineering, a labor-intensive step in traditional machine learning.\n",
        "\n",
        "Challenges with Depth (Vanishing and Exploding Gradients)\n",
        "\n",
        "**1. Vanishing Gradients:**\n",
        "As networks get deeper, gradients‚Äîa measure used to update network weights‚Äîcan become extremely small. This means the network stops (or becomes extremely slow) in learning and updating its weights, particularly in the early layers.\n",
        "\n",
        "Example: Consider an analogy where you're trying to teach a chain of people to relay a message. If the message gets weaker with each person it passes (like the gradient in a network), the last person might not get any information at all.\n",
        "\n",
        "**2. Exploding Gradients:**\n",
        "Conversely, gradients can also become too large, causing weights to update in an extremely aggressive manner. This leads to an unstable network with poor performance.\n",
        "\n",
        "\n",
        "**Example:** Using the same analogy, if the relayed message gets louder and more distorted with each person, the final message might be incomprehensible.\n",
        "\n",
        "To combat these challenges, various techniques like gradient clipping, batch normalization, and careful initialization methods are employed."
      ],
      "metadata": {
        "id": "2V9SZbAFlXOU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚òïLet's create a simple example to demonstrate deep neural networks using the popular deep learning library, **TensorFlow** and its high-level API **Keras**. This example will be on image classification using the **Fashion MNIST** **dataset**."
      ],
      "metadata": {
        "id": "qmrF80CBl-1B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep Neural Network Example: Fashion MNIST Image Classification\n",
        "\n",
        "Step 1: Import Libraries"
      ],
      "metadata": {
        "id": "_p7a1pvPmPm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n"
      ],
      "metadata": {
        "id": "sPOP5eftmSKM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Load the Fashion MNIST Dataset\n",
        "\n",
        "The dataset contains grayscale images of 10 fashion categories, with 60,000 images for training and 10,000 images for testing."
      ],
      "metadata": {
        "id": "oiLslDmOmU4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = keras.datasets.fashion_mnist.load_data()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vg7nNP4OmYBr",
        "outputId": "49e69a55-e286-43b2-a00b-d13c2534a607"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Preprocess the Data\n",
        "\n",
        "Normalize the image pixel values to the range [0,1]."
      ],
      "metadata": {
        "id": "VkKjnrYkmch-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.astype(\"float32\") / 255.0\n",
        "test_images = test_images.astype(\"float32\") / 255.0\n"
      ],
      "metadata": {
        "id": "h7JutmRsmfKC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Create the Deep Neural Network Model\n",
        "\n",
        "For demonstration purposes, we'll create a deep network with 3 dense layers."
      ],
      "metadata": {
        "id": "ntE1bxuimkEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)),  # Flatten input image\n",
        "    layers.Dense(128, activation='relu'),  # First dense layer with 128 neurons\n",
        "    layers.Dense(64, activation='relu'),   # Second dense layer with 64 neurons\n",
        "    layers.Dense(10, activation='softmax') # Output layer with 10 neurons (for 10 classes)\n",
        "])\n"
      ],
      "metadata": {
        "id": "mDHRoUeGmmzk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Compile the Model\n",
        "\n",
        "Here we define the optimizer, loss function, and metrics for training."
      ],
      "metadata": {
        "id": "cRhpqwQgmrwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "ngF6VSiJmueh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Train the Model\n",
        "\n",
        "We'll train the model for 10 epochs for this demonstration."
      ],
      "metadata": {
        "id": "VC-2Lq0Pmx_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels, epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INus-F8jm1Dp",
        "outputId": "5fc98862-5414-479c-f157-2987cf320372"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 0.5003 - accuracy: 0.8227\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3667 - accuracy: 0.8652\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3313 - accuracy: 0.8772\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3119 - accuracy: 0.8833\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2948 - accuracy: 0.8899\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2802 - accuracy: 0.8949\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2682 - accuracy: 0.8991\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2594 - accuracy: 0.9025\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2496 - accuracy: 0.9063\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2394 - accuracy: 0.9094\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a313cbe9b70>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Evaluate the Model\n",
        "We'll assess the model's performance on the test dataset."
      ],
      "metadata": {
        "id": "hGBkbNfsnTe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(f\"Test accuracy: {test_acc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCcX6cEMnVlH",
        "outputId": "cccd44b7-36c1-40c6-cd7e-eb04941cc5f4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 1s - loss: 0.3351 - accuracy: 0.8828 - 932ms/epoch - 3ms/step\n",
            "Test accuracy: 0.8827999830245972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "\n",
        "Step 1: We're importing necessary libraries.\n",
        "\n",
        "Step 2: Loading the dataset which contains various fashion items.\n",
        "\n",
        "Step 3: Normalize the image values. This helps the model converge faster during training.\n",
        "\n",
        "Step 4: Define our deep neural network. The model contains an input layer to flatten the images, two hidden layers with ReLU activation, and an output layer with Softmax activation for multi-class classification.\n",
        "\n",
        "Step 5: 'Compile' prepares the model for training. The optimizer adam is commonly used, and sparse_categorical_crossentropy is suitable for integer labels.\n",
        "\n",
        "Step 6: This step will start the training process. The model will learn to classify fashion items over 10 iterations (epochs) over the dataset.\n",
        "\n",
        "Step 7: After training, it's good practice to evaluate the model's performance on unseen data.\n",
        "\n",
        "By following these steps, you'll have a basic deep neural network ready for fashion image classification!"
      ],
      "metadata": {
        "id": "idK4tWf6nZZM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚û∞ Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) Networks\n",
        "\n",
        "Recurrent Neural Networks, or RNNs, are a type of neural network designed for sequences and lists of data. While conventional neural networks may struggle with sequential data, RNNs are explicitly built to recognize patterns across time.\n",
        "\n",
        "**Key Concepts:**\n",
        "\n",
        "\n",
        "**Sequence Handling**: Unlike feedforward neural networks, RNNs maintain hidden states that capture information about previous steps. This makes them perfect for tasks like time series prediction, natural language processing, and anything where the order of the data matters.\n",
        "\n",
        "**Vanishing & Exploding Gradients:**\n",
        "\n",
        " As sequences get long, RNNs can run into training difficulties. If the sequence is too long, they can forget information from earlier steps (vanishing gradient problem), or the information can blow up and become too dominant (exploding gradient problem).\n",
        "\n",
        "\n",
        "**LSTM & GRU:**\n",
        " To combat the issues of vanishing and exploding gradients, variants of RNNs like Long Short-Term Memory (LSTM) units and Gated Recurrent Units (GRU) were developed. These structures have 'gates' that control the flow of information, making them more effective in remembering long-term dependencies."
      ],
      "metadata": {
        "id": "aod-3Eo8oPXs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚òï Basic LSTM Example using PyTorch: Text Generation\n",
        "\n",
        "\n",
        "We'll build a simple character-level LSTM to generate new sequences of characters. For this example, let's consider generating new sequences after training on a sample sentence.\n",
        "\n",
        "\n",
        "Step 1: Import Libraries"
      ],
      "metadata": {
        "id": "cpafYjo9pBQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import string\n"
      ],
      "metadata": {
        "id": "DVowhbrfpLeQ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Data Preparation"
      ],
      "metadata": {
        "id": "_dlXRAZGpNx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello, there! How are you doing today?\"\n",
        "characters = string.ascii_letters + \" \" + string.punctuation + string.digits\n",
        "int2char = dict(enumerate(characters))\n",
        "char2int = {char: index for index, char in int2char.items()}\n"
      ],
      "metadata": {
        "id": "E7GxMN3ZpPp0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Define the LSTM Model"
      ],
      "metadata": {
        "id": "LY41ycfipTyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CharLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(CharLSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
        "\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "ws0aKFULpVsu"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a simple example, and we would typically include more data preprocessing, a training loop, and a text generation component. However, it serves as a foundational introduction to how we can construct and think about RNNs, especially LSTMs, in PyTorch.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BnvFQI0CpYv2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚ôê Convolutional Neural Networks (CNNs)\n",
        "\n",
        "\n",
        "Convolutional Neural Networks, often referred to as CNNs or ConvNets, are a class of deep neural networks commonly used to analyze visual imagery. They're especially potent at processing the spatial structure in data, making them the go-to model for image recognition tasks.\n",
        "\n",
        "**Key Concepts:**\n",
        "\n",
        "Convolutional Layer: This is the core of a CNN. It filters an input data (like an image) to produce a feature map, effectively transforming the input data.\n",
        "\n",
        "Pooling/Subsampling: Reduces the spatial size of the representation to reduce the amount of parameters and computation. Max pooling is a common technique, where the maximum value is taken from a patch of an image.\n",
        "\n",
        "\n",
        "**Flattening:** After convolutional and pooling layers, the final matrix is converted into a single linear vector, serving as an input to the final classification model.\n",
        "\n",
        "\n",
        "**Fully Connected Layer:** Neurons in a fully connected layer have connections to all activations in the previous layer. This part of the network typically looks similar to the standard multi-layer perceptrons."
      ],
      "metadata": {
        "id": "bYw_uz09pfA7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic CNN Example using PyTorch: Image Classification ‚òï\n",
        "\n",
        "\n",
        "**Let's say we aim to classify an image as either a cat or a dog.**"
      ],
      "metadata": {
        "id": "RPLA8YHxpvHL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Import Libraries"
      ],
      "metadata": {
        "id": "KZ2xzCTwp27t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n"
      ],
      "metadata": {
        "id": "E9gqHjDvp4_F"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Data Loading"
      ],
      "metadata": {
        "id": "AhN4HkcQp71V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oy6m4ZKqDBX",
        "outputId": "0a9012a9-4db6-43f9-e4a6-93ecbd7a5f9b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 170498071/170498071 [00:01<00:00, 93050283.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Define the CNN Model"
      ],
      "metadata": {
        "id": "BRD5ifQqqWQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "Pf9OvOICqYIp"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This simple model contains two convolutional layers, followed by max pooling, and three fully connected layers. The model is quite basic and serves to illustrate the components of a CNN. In practice, CNNs, especially for complex tasks, can be much deeper and more sophisticated."
      ],
      "metadata": {
        "id": "29U8CLZBqbNa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚õ∫ Recurrent Neural Networks (RNNs)\n",
        "\n",
        "Recurrent Neural Networks, or RNNs, are a category of neural networks designed for sequential data. They have internal loops to allow information persistence. They're particularly suitable for tasks like speech recognition, natural language processing, and time-series forecasting.\n",
        "\n",
        "**Key Concepts:**\n",
        "\n",
        "**Memory Cells:** These are the components in RNNs that store the previous outputs and pass them back into the network to affect future outputs.\n",
        "\n",
        "**Vanishing & Exploding Gradient Problem:** Due to their nature, RNNs are prone to these issues during training. LSTMs and GRUs (variations of RNNs) are introduced to counter these problems.\n",
        "\n",
        "**Long Short-Term Memory (LSTM):** A special kind of RNN that is designed to remember information for long periods. It has a more complex internal structure than standard RNNs.\n",
        "\n",
        "**Gated Recurrent Unit (GRU):** Another RNN variant similar to LSTM but with a simpler structure."
      ],
      "metadata": {
        "id": "PsRtcG0Oqe22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚òï Basic RNN Example using PyTorch: Sequence Classification\n",
        "\n",
        "Imagine we're trying to determine the sentiment of a sentence (positive or negative)."
      ],
      "metadata": {
        "id": "mMxxBVrEq06L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Import Libraries"
      ],
      "metadata": {
        "id": "VT9elc46q-Ni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n"
      ],
      "metadata": {
        "id": "Uu1WrbIHrAqJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Define the RNN Model"
      ],
      "metadata": {
        "id": "fo4BkKhFrDUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SimpleRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        out = out[:, -1, :]\n",
        "        out = self.fc(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "mO3HbhD5rFbE"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model defined above consists of a basic RNN layer followed by a fully connected layer to produce the final output. This model can take sequences (e.g., sentences represented as vectors) and classify them based on the last output from the RNN layer.\n",
        "\n",
        "To make this model more effective for real-world applications, one might consider using LSTMs or GRUs instead of the standard RNN layer, adding more layers, or employing techniques like dropout for regularization."
      ],
      "metadata": {
        "id": "6fxvTmp0rIu9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚õ≤ Transfer Learning\n",
        "\n",
        "In the world of Deep Learning, training a model from scratch requires a significant amount of data and computational power. But what if we could leverage the knowledge acquired from training on one task and apply it to another? That's where transfer learning comes into play.\n",
        "\n",
        "\n",
        "**What is Transfer Learning?**\n",
        "\n",
        "Transfer Learning is a machine learning technique where a model developed for a particular task is reused as the starting point for a model on a second task. Instead of starting the learning process from scratch, you start from patterns that have been learned while solving a different problem. This technique is particularly beneficial when:\n",
        "\n",
        "\n",
        "You have a small dataset.\n",
        "\n",
        "The initial task is similar to the new task you're tackling.\n",
        "\n",
        "Pre-trained Models\n",
        "\n",
        "A pre-trained model is a model that has been previously trained on a large dataset, typically on a large-scale image classification task. These models can be used as is, if the categories in the pre-trained model are the ones you need, or they can serve as a base to develop a model tailored to your specific task.\n",
        "\n",
        "\n",
        "**Popular sources of pre-trained models include:**\n",
        "\n",
        "VGG16, VGG19: Models from the Visual Geometry Group at Oxford, trained on the ImageNet dataset.\n",
        "\n",
        "ResNet: Introduced by Microsoft Research, it includes several variants like ResNet-50, ResNet-101, and ResNet-152.\n",
        "\n",
        "MobileNet: Google's model optimized for speed and size, making it good for mobile applications.\n",
        "\n",
        "InceptionV3: Another model by Google, trained for the ImageNet Large Visual Recognition Challenge.\n",
        "\n",
        "*** Most of these models are accessible through deep learning frameworks like TensorFlow and PyTorch.**\n",
        "\n",
        "**Fine-tuning Pre-trained Models**\n",
        "\n",
        "Fine-tuning involves slightly adjusting the weights of an already trained model to make it suitable for the new task. Here's how it typically works:\n",
        "\n",
        "Feature Extraction: Use the representations learned by a previous network to extract meaningful features from new samples. You simply add a new classifier, which will be trained from scratch, on top of the pre-trained model.\n",
        "\n",
        "**Fine-tuning:** Unfreeze a few top layers from the model and train them along with the newly added classifier.\n",
        "\n",
        "\n",
        "**Training: **Use the smaller dataset you have to train the model. Since the weights have already been optimized on a larger dataset, the model will be able to generalize well even with a smaller dataset."
      ],
      "metadata": {
        "id": "ILjoCP7PrRpX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example using TensorFlow:"
      ],
      "metadata": {
        "id": "PyzUO2bvr0Hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "# Load the VGG16 model with weights pre-trained on ImageNet\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the layers of the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create a new model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the base model\n",
        "model.add(base_model)\n",
        "\n",
        "# Flatten the output to feed into a Dense layer\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add a Dense layer\n",
        "model.add(Dense(256, activation='relu'))\n",
        "\n",
        "# Output layer for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile and train the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBdA683Dr5Al",
        "outputId": "5b7c7471-07cd-4105-c5bd-ca117aaafd39"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By fine-tuning a pre-trained model, you can achieve impressive results even with a smaller dataset. This is particularly useful in domains where obtaining large amounts of labeled data is challenging."
      ],
      "metadata": {
        "id": "zkFzHKjgr9VN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚öì Regularization and Optimization\n",
        "\n",
        "When training deep learning models, there's always a risk of overfitting. Overfitting occurs when a model performs exceptionally well on the training data but poorly on unseen data. To address this, we use regularization techniques. Additionally, optimizing neural networks can be challenging given their complex nature. Let's delve into some techniques that help in regularization and optimization.\n",
        "\n",
        "**Dropout**\n",
        "\n",
        "Dropout is a regularization method that involves dropping out or \"deactivating\" a fraction of neurons during training. This means that during each training iteration, certain neurons won't be updated. By doing this, dropout forces the network to be more robust and prevents co-adaptation of neurons."
      ],
      "metadata": {
        "id": "If4oFJs2sAVy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usage with TensorFlow:"
      ],
      "metadata": {
        "id": "Dz907L2ysL9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules and functions\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# Define input_shape based on your data\n",
        "# For demonstration, let's assume your data has the shape (28, 28)\n",
        "input_shape = (28, 28)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(256, activation='relu', input_shape=input_shape))\n",
        "model.add(Dropout(0.5))  # Drop 50% of neurons in the previous layer during training\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n"
      ],
      "metadata": {
        "id": "NdvG1_UasN-y"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch Normalization\n",
        "Batch Normalization (BatchNorm) is a technique designed to automatically standardize the inputs of a layer in a deep network, helping in faster training and requiring less care about initialization. It normalizes the activations of a given input volume before passing it to the next layer.\n",
        "\n",
        "Usage with TensorFlow:"
      ],
      "metadata": {
        "id": "RBGzje8F2sHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization\n",
        "\n",
        "# Define input_shape based on your data\n",
        "# For demonstration, let's assume your data has a shape of (784,) for a flattened 28x28 image\n",
        "input_shape = (784,)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(256, activation='relu', input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n"
      ],
      "metadata": {
        "id": "lEJP1kb_2vLZ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimization Techniques**\n",
        "\n",
        "Optimizers are algorithms used to update and compute weights and biases. Several optimization techniques have been proposed to speed up convergence and improve the training process:\n",
        "\n",
        "**Adam (Adaptive Moment Estimation):**Combines the advantages of two other extensions of stochastic gradient descent, namely AdaGrad and RMSprop. Adam computes adaptive learning rates for each parameter. In addition to storing an exponentially decaying average of past squared gradients like RMSprop, Adam also keeps an exponentially decaying average of past gradients.\n",
        "\n",
        "**RMSprop (Root Mean Square Propagation):** Maintains a moving average of the squared gradient. It uses this average to normalize the gradient.\n",
        "\n",
        "\n",
        "Usage with TensorFlow:"
      ],
      "metadata": {
        "id": "kHmpt64S8uqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "\n",
        "# Using Adam optimizer\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Using RMSprop optimizer\n",
        "model.compile(optimizer=RMSprop(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "wWuPoLwo841A"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choosing the right optimization technique can greatly affect the speed of convergence and the final performance of the model. Usually, Adam is a good starting point for many tasks as it balances the benefits of both AdaGrad and RMSprop. However, it's always beneficial to experiment with different optimizers and learning rates to see which works best for a specific problem."
      ],
      "metadata": {
        "id": "d3ZWghBU88Nb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üî∞ Tools and Libraries\n",
        "\n",
        "In the rapidly evolving landscape of deep learning, two libraries stand out due to their ease of use, flexibility, and extensive capabilities: PyTorch and TensorFlow. These libraries, combined with platforms like Google Colab, provide researchers, data scientists, and enthusiasts with the perfect environment to develop and explore deep learning models.\n",
        "\n",
        "**Introduction to PyTorch and TensorFlow**\n",
        "\n",
        "PyTorch: Developed by Facebook's AI Research lab, PyTorch is known for its dynamic computation graph, which makes it particularly useful for research and development. Its intuitive interface allows for easy debugging and is often preferred by researchers in academia.\n",
        "\n",
        "\n",
        "**TensorFlow:** Created by Google, TensorFlow is designed for production deployment in mind. It operates on a static computation graph, which needs to be defined and run separately. TensorFlow 2.x has introduced tf.keras, a high-level API for building and training deep learning models, making it more user-friendly.\n",
        "\n",
        "\n",
        "**Setting up Google Colab**\n",
        "\n",
        "Google Colab is a free, cloud-based platform that offers GPU support, making it an ideal environment for training deep learning models without any setup on your local machine.\n",
        "\n",
        "**Steps to set up Google Colab:**\n",
        "\n",
        "Go to Google Colab.\n",
        "\n",
        "Create a new notebook via File > New notebook.\n",
        "\n",
        "To enable GPU, click on Runtime > Change runtime type, select GPU from the dropdown and save.\n",
        "\n",
        "Now, you can write and execute Python code. It also supports installing packages via pip.\n",
        "\n",
        "\n",
        "**Example: Building a Simple Deep Learning Model using PyTorch**"
      ],
      "metadata": {
        "id": "PICOGwhJ9Bk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, we'll install PyTorch in the Colab environment\n",
        "!pip install torch torchvision\n",
        "\n",
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define a simple feedforward neural network\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "model = SimpleNN(input_dim=10, hidden_dim=20, output_dim=1)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Sample data\n",
        "inputs = torch.randn(5, 10)\n",
        "targets = torch.randn(5, 1)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/100], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5wi6uyl9c3F",
        "outputId": "ebf02725-767e-4baf-b215-c172febad728"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Epoch [10/100], Loss: 0.4691\n",
            "Epoch [20/100], Loss: 0.0776\n",
            "Epoch [30/100], Loss: 0.0119\n",
            "Epoch [40/100], Loss: 0.0184\n",
            "Epoch [50/100], Loss: 0.0010\n",
            "Epoch [60/100], Loss: 0.0018\n",
            "Epoch [70/100], Loss: 0.0009\n",
            "Epoch [80/100], Loss: 0.0001\n",
            "Epoch [90/100], Loss: 0.0001\n",
            "Epoch [100/100], Loss: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code demonstrates how to create a simple feedforward neural network using PyTorch, define a loss function and optimizer, and train the model using a training loop. It showcases the fundamental steps involved in building and training a deep learning model using PyTorch on Google Colab."
      ],
      "metadata": {
        "id": "X7NetIrr9yVw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚õ≥ Conclusion and Future Trends\n",
        "\n",
        "**Current Achievements in Deep Learning**\n",
        "\n",
        "Deep Learning has ushered in a transformative era in the realm of artificial intelligence, driving advancements across diverse fields:\n",
        "\n",
        "**Computer Vision: **\n",
        "Object detection, facial recognition, and image generation using Generative Adversarial Networks (GANs) have seen significant breakthroughs, making applications like automated surveillance, augmented reality, and personalized avatars possible.\n",
        "\n",
        "\n",
        "**Natural Language Processing (NLP):** Transformer architectures, particularly models like BERT and GPT-3, have achieved human-par performance in tasks like text generation, translation, and question-answering.\n",
        "\n",
        "\n",
        "**Medicine:** Deep Learning models assist doctors in diagnosing diseases with higher accuracy by analyzing medical images, predicting patient deterioration, or even synthesizing new potential drugs.\n",
        "\n",
        "\n",
        "**Autonomous Vehicles:** Deep learning powers the perception and decision-making capabilities of self-driving cars, ensuring safer and more efficient roads.\n",
        "\n",
        "\n",
        "**Gaming: **AI agents trained using deep reinforcement learning have outperformed humans in complex games like Go, Poker, and multi-player online games.\n",
        "\n",
        "## Potential Future Developments and Challenges\n",
        "\n",
        "As promising as the current landscape of deep learning appears, the horizon is dotted with numerous possibilities and challenges:\n",
        "\n",
        "**Explainable AI:** As deep learning models become more intricate, their decision-making process becomes harder to interpret. The future will emphasize models that are not only accurate but also transparent in how they reach conclusions.\n",
        "\n",
        "**Few-shot and Zero-shot Learning:** While current models require vast amounts of data to train, future models might achieve similar accuracy with minimal data or even in scenarios they haven't encountered before.\n",
        "\n",
        "**Edge Computing:** With the increasing need for real-time processing in devices like drones and IoT gadgets, deep learning models' efficiency and size will be optimized for local processing rather than relying on cloud servers.\n",
        "\n",
        "\n",
        "**Hybrid Models:** Integrating symbolic reasoning with deep learning might pave the way for models that combine the best of rule-based logic and neural network adaptability.\n",
        "\n",
        "\n",
        "**Ethical Concerns:** As AI becomes increasingly integrated into daily life, concerns about privacy, data security, and potential misuse will need to be addressed. Creating models that are fair and free from biases will also be a significant focus.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "In conclusion, while deep learning has revolutionized numerous domains with its current achievements, the journey ahead is rife with opportunities and challenges. Embracing these, the AI community is poised to steer deep learning towards a future that might reshape human-machine interaction fundamentally."
      ],
      "metadata": {
        "id": "24U83t2Q92AV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚òï Examples with codes and Explanations\n",
        "\n",
        "1- Feedforward Neural Networks\n",
        "\n",
        "2- Convolutional Neural Networks (CNNs)\n",
        "\n",
        "3- Recurrent Neural Networks (RNNs) and LSTM\n",
        "\n",
        "4- Transfer Learning\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CCzv_a3c-tck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's take some of the topics from your Table of Contents and delve deeper with examples and explanations.**\n",
        "\n",
        "## Feedforward Neural Networks\n",
        "\n",
        "Feedforward Neural Networks are the simplest type of artificial neural network architecture. Here, the data flows from the input layer to the output layer without looping back. Let's create a simple feedforward neural network for binary classification."
      ],
      "metadata": {
        "id": "6xBD28nt_UHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Create a Feedforward Neural Network\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(784,)), # Assume input is a flattened 28x28 image\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "gYunfG_P_ZFA"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Neural Networks (CNNs)\n",
        "\n",
        "CNNs are primarily used for image processing tasks. They contain convolutional layers that apply convolutional operations to the input data.\n",
        "\n",
        "Here's a basic CNN structure for image classification:"
      ],
      "metadata": {
        "id": "tq7M416J_cdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)), # Assume grayscale 28x28 images\n",
        "    MaxPooling2D(2,2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax') # Assume 10 classes for classification\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "8mpMcWcu_hX_"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recurrent Neural Networks (RNNs) and LSTM\n",
        "\n",
        "RNNs are designed to recognize patterns in sequences of data, like text, genomes, time series, etc. Let's create a basic RNN model for sequence classification:"
      ],
      "metadata": {
        "id": "nP8nw7-f_kfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import SimpleRNN, Embedding\n",
        "\n",
        "max_features = 10000  # Number of words to consider as features\n",
        "maxlen = 500  # Cut sequences after this number of words\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(max_features, 32),\n",
        "    SimpleRNN(32),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "QCFehxPb_oIF"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer Learning\n",
        "\n",
        "Transfer learning allows us to leverage a pre-trained model (usually on a large dataset) and adjust it for our specific task. Let's employ a pre-trained model from Keras's applications:"
      ],
      "metadata": {
        "id": "3K_qFIlU_rNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "# Load the VGG16 network with weights pre-trained on ImageNet\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))  # Assuming a 150x150 RGB image\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Freeze the layers of the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "qHXF4AeA_x7Q"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üß† **Deep Learning Thesaurus**\n",
        "\n",
        "## Table of Contents\n",
        "- [Deep Learning](#deep-learning)\n",
        "  - [Synonyms](#synonyms-for-deep-learning)\n",
        "  - [Brief](#brief-on-deep-learning)\n",
        "- [Activation Function](#activation-function)\n",
        "  - [Synonyms](#synonyms-for-activation-function)\n",
        "  - [Brief](#brief-on-activation-function)\n",
        "- [Backpropagation](#backpropagation)\n",
        "  - [Synonyms](#synonyms-for-backpropagation)\n",
        "  - [Brief](#brief-on-backpropagation)\n",
        "- [Convolutional Neural Network (CNN)](#convolutional-neural-network-cnn)\n",
        "  - [Synonyms](#synonyms-for-cnn)\n",
        "  - [Brief](#brief-on-cnn)\n",
        "- [Recurrent Neural Network (RNN)](#recurrent-neural-network-rnn)\n",
        "  - [Synonyms](#synonyms-for-rnn)\n",
        "  - [Brief](#brief-on-rnn)\n",
        "- [Long Short-Term Memory (LSTM)](#long-short-term-memory-lstm)\n",
        "  - [Synonyms](#synonyms-for-lstm)\n",
        "  - [Brief](#brief-on-lstm)\n",
        "\n",
        "---\n",
        "\n",
        "## Deep Learning\n",
        "### Synonyms for Deep Learning\n",
        "- Neural networks\n",
        "- Artificial neural networks (ANN)\n",
        "- Deep architectures\n",
        "\n",
        "### Brief on Deep Learning\n",
        "A subset of machine learning, deep learning employs multi-layered neural networks inspired by the human brain to model data.\n",
        "\n",
        "---\n",
        "\n",
        "## Activation Function\n",
        "### Synonyms for Activation Function\n",
        "- Transfer function\n",
        "- Activation\n",
        "- Non-linearity\n",
        "\n",
        "### Brief on Activation Function\n",
        "It introduces non-linearity in neural networks, enabling them to learn intricate data patterns.\n",
        "\n",
        "---\n",
        "\n",
        "## Backpropagation\n",
        "### Synonyms for Backpropagation\n",
        "- Backward propagation of errors\n",
        "- Delta rule\n",
        "- Gradient descent optimization\n",
        "\n",
        "### Brief on Backpropagation\n",
        "An algorithm that adjusts neural network weights to minimize prediction errors.\n",
        "\n",
        "---\n",
        "\n",
        "## Convolutional Neural Network (CNN)\n",
        "### Synonyms for CNN\n",
        "- ConvNet\n",
        "- Shift invariant or space invariant artificial neural network (SIANN)\n",
        "\n",
        "### Brief on CNN\n",
        "A deep learning variant primarily for visual imagery analysis using convolutional layers.\n",
        "\n",
        "---\n",
        "\n",
        "## Recurrent Neural Network (RNN)\n",
        "### Synonyms for RNN\n",
        "- Cyclic network\n",
        "- Sequence model\n",
        "\n",
        "### Brief on RNN\n",
        "Neural networks with memory capabilities, making them apt for sequential data processing.\n",
        "\n",
        "---\n",
        "\n",
        "## Long Short-Term Memory (LSTM)\n",
        "### Synonyms for LSTM\n",
        "- Memory cell\n",
        "- Gated recurrent unit (related, but not a direct synonym)\n",
        "\n",
        "### Brief on LSTM\n",
        "An RNN type less prone to the vanishing gradient problem, capable of learning across long sequences.\n"
      ],
      "metadata": {
        "id": "BBGeUTQnDWk7"
      }
    }
  ]
}